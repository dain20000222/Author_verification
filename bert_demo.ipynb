{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XN8cyfgM4qwd","outputId":"13d2f458-d9c2-4183-ace0-64d69418b285","executionInfo":{"status":"ok","timestamp":1713834551283,"user_tz":-60,"elapsed":2321,"user":{"displayName":"김다인","userId":"16444758152282076704"}}},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["cd drive/MyDrive/Colab Notebooks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AGsIcey44xVx","outputId":"dc0c20ac-e294-4c32-ef8f-816b909dc99b","executionInfo":{"status":"ok","timestamp":1713834551283,"user_tz":-60,"elapsed":4,"user":{"displayName":"김다인","userId":"16444758152282076704"}}},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'drive/MyDrive/Colab Notebooks'\n","/content/drive/MyDrive/Colab Notebooks\n"]}]},{"cell_type":"markdown","source":["Import library"],"metadata":{"id":"BVZ1_tDMWBFF"}},{"cell_type":"code","execution_count":36,"metadata":{"id":"qCrsN9iZ4h3L","executionInfo":{"status":"ok","timestamp":1713834551283,"user_tz":-60,"elapsed":2,"user":{"displayName":"김다인","userId":"16444758152282076704"}}},"outputs":[],"source":["import torch\n","import pandas as pd\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import DistilBertTokenizer, DistilBertModel\n","from torch import nn, optim\n","from torch.nn.functional import sigmoid"]},{"cell_type":"markdown","source":["BERT model"],"metadata":{"id":"HbakOe7IDvbA"}},{"cell_type":"code","source":["# A custom dataset class for a Siamese network class utilizing a BERT model for embedding text pairs\n","class SiameseBERT(nn.Module):\n","    # Initialize the Siamese BERT model with a pretrained BERT model and additional layers\n","    def __init__(self, bert_model, hidden_size=768, output_size=1):\n","        super().__init__()\n","        self.bert = bert_model\n","        self.dense = nn.Linear(hidden_size, hidden_size)\n","        self.output = nn.Linear(hidden_size, output_size)\n","\n","    # Applies mean pooling to the last hidden states of BERT outputs using an attention mask\n","    def mean_pooling(self, model_output, attention_mask):\n","        # Extract the last hidden states as token embeddings\n","        token_embeddings = model_output.last_hidden_state\n","\n","        # Expand the attention mask for element-wise multiplication\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","\n","        # Sum the embddings while applying the mask\n","        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n","\n","        # Compute sum of the mask with a clamp\n","        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n","\n","        # Return the mean pooled embeddings\n","        return sum_embeddings / sum_mask\n","\n","    # Defines the forward pass for the SiameseBERT network with two input sequences\n","    def forward(self, input_ids_a, attention_mask_a, input_ids_b, attention_mask_b):\n","        # Get the output from BERT for both sequences\n","        output_a = self.bert(input_ids_a, attention_mask=attention_mask_a)\n","        output_b = self.bert(input_ids_b, attention_mask=attention_mask_b)\n","\n","        # Perform mean pooling on the outputs\n","        pooled_output_a = self.mean_pooling(output_a, attention_mask_a)\n","        pooled_output_b = self.mean_pooling(output_b, attention_mask_b)\n","\n","        # Pass through the dense layer\n","        dense_output_a = torch.relu(self.dense(pooled_output_a))\n","        dense_output_b = torch.relu(self.dense(pooled_output_b))\n","\n","        # Compute distance metric\n","        combined_output = torch.abs(dense_output_a - dense_output_b)\n","        logits = self.output(combined_output)\n","\n","        return logits"],"metadata":{"id":"71V6IHSwSlUD","executionInfo":{"status":"ok","timestamp":1713834551283,"user_tz":-60,"elapsed":2,"user":{"displayName":"김다인","userId":"16444758152282076704"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# Load model\n","model = SiameseBERT(DistilBertModel.from_pretrained('distilbert-base-uncased'))\n","state_dict = torch.load(\"./NLU/bert.pth\")\n","model.load_state_dict(state_dict)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u2wjskFg_WOU","outputId":"87606ee9-030b-43eb-e3f3-4f9076350bd1","executionInfo":{"status":"ok","timestamp":1713834552976,"user_tz":-60,"elapsed":1695,"user":{"displayName":"김다인","userId":"16444758152282076704"}}},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SiameseBERT(\n","  (bert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0-5): 6 x TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (dense): Linear(in_features=768, out_features=768, bias=True)\n","  (output): Linear(in_features=768, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["Test data"],"metadata":{"id":"lICKeHvaW5Y6"}},{"cell_type":"code","source":["# Load test data\n","test = pd.read_csv('./NLU/test.csv')\n","\n","# Replace na values in text columns with an empty string\n","test['text_1'] = test['text_1'].fillna('')\n","test['text_2'] = test['text_2'].fillna('')"],"metadata":{"id":"EFG6-WcsHVT7","executionInfo":{"status":"ok","timestamp":1713834552977,"user_tz":-60,"elapsed":3,"user":{"displayName":"김다인","userId":"16444758152282076704"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# A custom dataset class for test data\n","class TestDataset(Dataset):\n","    # Initialize the dataset with text pairs and a tokenizer\n","    def __init__(self, texts_a, texts_b, tokenizer, max_len=512):\n","        self.texts_a = texts_a\n","        self.texts_b = texts_b\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    # Return the total number of items in the dataset\n","    def __len__(self):\n","        return len(self.texts_a)\n","\n","    # Return the encoded pair of texts at the given index\n","    def __getitem__(self, idx):\n","        text_a = self.texts_a[idx]\n","        text_b = self.texts_b[idx]\n","\n","        encoding_a = tokenizer.encode_plus(\n","            text_a,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","        )\n","\n","        encoding_b = tokenizer.encode_plus(\n","            text_b,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","        )\n","\n","        return {\n","            'input_ids_a': encoding_a['input_ids'].squeeze(0),\n","            'attention_mask_a': encoding_a['attention_mask'].squeeze(0),\n","            'input_ids_b': encoding_b['input_ids'].squeeze(0),\n","            'attention_mask_b': encoding_b['attention_mask'].squeeze(0)\n","        }"],"metadata":{"id":"lhcqYxX6J5JD","executionInfo":{"status":"ok","timestamp":1713834552977,"user_tz":-60,"elapsed":2,"user":{"displayName":"김다인","userId":"16444758152282076704"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["# Load the DistilBERT tokenizer\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","\n","testset = TestDataset(test['text_1'].tolist(), test['text_2'].tolist(), tokenizer)\n","test_loader = DataLoader(testset, batch_size=32, shuffle=False)"],"metadata":{"id":"ig_lTIZhJds5","executionInfo":{"status":"ok","timestamp":1713834552977,"user_tz":-60,"elapsed":2,"user":{"displayName":"김다인","userId":"16444758152282076704"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["# Generate predictions for the given data loader\n","def generate_predictions(model, data_loader):\n","    model.eval()\n","    predictions = []\n","\n","    # Deactivate gradients for evaluation\n","    with torch.no_grad():\n","        for batch in data_loader:\n","            input_ids_a = batch['input_ids_a'].to(device)\n","            attention_mask_a = batch['attention_mask_a'].to(device)\n","            input_ids_b = batch['input_ids_b'].to(device)\n","            attention_mask_b = batch['attention_mask_b'].to(device)\n","\n","            # Apply sigmoid to output logits\n","            outputs = model(input_ids_a, attention_mask_a, input_ids_b, attention_mask_b)\n","            preds = sigmoid(outputs).squeeze().cpu().numpy()\n","            predictions.extend(preds)\n","    return predictions"],"metadata":{"id":"F2evgsvhITeP","executionInfo":{"status":"ok","timestamp":1713834552977,"user_tz":-60,"elapsed":2,"user":{"displayName":"김다인","userId":"16444758152282076704"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["Testing model on test data"],"metadata":{"id":"9LCAngHHIqJ3"}},{"cell_type":"code","source":["# Generate predictions for the test dataset\n","predictions = generate_predictions(model, test_loader)\n","result_df = pd.DataFrame(predictions, columns=['prediction'])\n","\n","# Convert probabilities to binary labels using a threshold = 0.5\n","best_threshold = 0.5\n","predicted_labels = (result_df['prediction'] > best_threshold).astype(int)"],"metadata":{"id":"2LRKbPomIWKX","executionInfo":{"status":"ok","timestamp":1713834780890,"user_tz":-60,"elapsed":227915,"user":{"displayName":"김다인","userId":"16444758152282076704"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["result_df = pd.DataFrame(predicted_labels, columns=['prediction'])\n","result_df.to_csv(\"./NLU/Group_21_C.csv\", index=False)"],"metadata":{"id":"77bfuT4HI_se","executionInfo":{"status":"ok","timestamp":1713834780891,"user_tz":-60,"elapsed":14,"user":{"displayName":"김다인","userId":"16444758152282076704"}}},"execution_count":44,"outputs":[]}]}